{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mxhs5BtVTJH5"
      },
      "source": [
        "# 1. Implementar un perceptrón en Python"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uNe_1MX-TJH-"
      },
      "source": [
        "Implementa un perceptrón funcional en Python utilizando la librería NumPy, y utilízalo para hacer una predicción sobre el dataset de breast_cancer de sklearn. Para ello, ve rellenando la clase que hay en este notebook, siguiendo los siguientes subapartados:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ffvquzVdTJH_"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "class Perceptron:\n",
        "    \"\"\"Perceptron classifier.\n",
        "    Parameters\n",
        "    ------------\n",
        "    eta : float\n",
        "      Learning rate (between 0.0 and 1.0)\n",
        "    n_iter : int\n",
        "      Passes over the training dataset.\n",
        "    random_state : int\n",
        "      Random number generator seed for random weight\n",
        "      initialization.\n",
        "    Attributes\n",
        "    -----------\n",
        "    w_ : 1d-array\n",
        "      Weights after fitting.\n",
        "    b_ : Scalar\n",
        "      Bias unit after fitting.\n",
        "    errors_ : list\n",
        "      Number of misclassifications (updates) in each epoch.\n",
        "    \"\"\"\n",
        "    def __init__(self, eta=0.01, n_iter=50, random_state=1):\n",
        "        self.eta = eta\n",
        "        self.n_iter = n_iter\n",
        "        self.random_state = random_state\n",
        "        rgen = np.random.RandomState(self.random_state)\n",
        "        self.w_ = rgen.normal(loc=0.0, scale=0.01, size=X.shape[1])\n",
        "        self.b_ = np.float_(0.)\n",
        "        self.errors_ = []\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        \"\"\"Ajusta los vectores de X a la clase y.\n",
        "        Parámetros\n",
        "        ----------\n",
        "        X : {array-like}, shape = [n_examples, n_features]\n",
        "          Vectores de entrenamiento, donde n_examples es el número de vectores,\n",
        "          y n_features, el número de features por cada vector.\n",
        "        y : array-like, shape = [n_examples]\n",
        "          Vector de ground truth.\n",
        "        Returns\n",
        "        -------\n",
        "        self : object\n",
        "        \"\"\"\n",
        "\n",
        "    def net_input(self, X):\n",
        "        \"\"\"Calcula el net input entre X y W\"\"\"\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"Retorna la clase a la que pertenece el registro X\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bvYMnJyRTJIB"
      },
      "source": [
        "1.1. Observa la función \"\\_\\_init\\_\\_\". Esta función contiene los parámetros con los que se inicializará nuestro perceptrón, y que serán accesibles por todos los métodos de la clase. \"eta\" es el learning_rate, \"n_iter\" es el número de iteraciones que se harán sobre el conjunto de entrenamiento, \"random_state\" es la semilla para inicializar los valores aleatorios de $W$, \"w_\" es el vector $W$, \"b_\" es la unidad de sesgo o *bias*, y \"errors_\" indica el número de errores cometidos durante el entrenamiento."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wrh62ikvTJIC"
      },
      "source": [
        "1.2. Implementa la función \"net_input\", que recibirá un vector de valores $X$, y devolverá el **net input** de $X$ y $W$. Utiliza NumPy para realizar la operación producto punto."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rRiVtB9uTJID"
      },
      "source": [
        "1.3. Implementa la función \"predict\", que te devuelva la predicción de la clase a la que pertenece un registro $X$. Recuerda que el perceptrón devuelve clase 1 si el \"net_input\" de $X$ y $W$ es superior a 0, ó clase 0 en caso contrario."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kr9K2cAgTJID"
      },
      "source": [
        "1.4. Implementa la función \"fit\", que ejecute el algoritmo del perceptrón. Recuerda su definición:\n",
        "1. Definimos el número de iteraciones sobre el conjunto de datos (nuestro parámetro que ya definimos en la función \"\\_\\_init\\_\\_\", \"n_iter\").\n",
        "2. Por cada iteración sobre el conjunto de datos, iteramos sobre cada registro que tengamos.\n",
        "3. Por cada registro de nuestro conjunto de datos, predecimos a qué clase pertenece dicho registro.\n",
        "4. Una vez tengamos la clase predicha, computamos el error y el valor actualizado de $W$ y $b$.\n",
        "5. Actualizamos $W$ y $b$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XzOFkjS3TJIE"
      },
      "source": [
        "1.5. Añade a la función \"fit\" código para que almacene en la lista \"errors_\" (atributo de nuestra clase), por cada iteración sobre el conjunto de datos, el número de predicciones fallidas en dicha iteración."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1oZJrNKsTJIE"
      },
      "source": [
        "1.6. Con tu perceptrón funcional, utilízalo para predecir sobre un dataset de prueba:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mtK9RKo8TJIE"
      },
      "outputs": [],
      "source": [
        "### --------------------------------------------------------------- ###\n",
        "# Ejecuta esta celda: contiene funciones que necesitarás más adelante #\n",
        "### --------------------------------------------------------------- ###\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "def plot_errors_over_epochs(model: Perceptron):\n",
        "    from matplotlib import pyplot as plt\n",
        "    plt.plot(range(1, len(model.errors_) + 1), model.errors_, marker='o')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Number of updates')\n",
        "    plt.show()\n",
        "\n",
        "def plot_decision_regions(X, y, classifier, resolution=0.02):\n",
        "    from matplotlib import pyplot as plt\n",
        "    from matplotlib.colors import ListedColormap\n",
        "\n",
        "    # setup marker generator and color map\n",
        "    markers = ('o', 's', '^', 'v', '<')\n",
        "    colors = ('red', 'blue', 'lightgreen', 'gray', 'cyan')\n",
        "    cmap = ListedColormap(colors[:len(np.unique(y))])\n",
        "\n",
        "    # plot the decision surface\n",
        "    x1_min, x1_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
        "    x2_min, x2_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
        "    xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, resolution),\n",
        "                           np.arange(x2_min, x2_max, resolution))\n",
        "    lab = classifier.predict(np.array([xx1.ravel(), xx2.ravel()]).T)\n",
        "    lab = lab.reshape(xx1.shape)\n",
        "    plt.contourf(xx1, xx2, lab, alpha=0.3, cmap=cmap)\n",
        "    plt.xlim(xx1.min(), xx1.max())\n",
        "    plt.ylim(xx2.min(), xx2.max())\n",
        "\n",
        "    # plot class examples\n",
        "    for idx, cl in enumerate(np.unique(y)):\n",
        "        plt.scatter(x=X[y == cl, 0],\n",
        "                    y=X[y == cl, 1],\n",
        "                    alpha=0.8,\n",
        "                    c=colors[idx],\n",
        "                    marker=markers[idx],\n",
        "                    label=f'Class {cl}',\n",
        "                    edgecolor='black')\n",
        "    plt.xlabel('Sepal length [cm]')\n",
        "    plt.ylabel('Petal length [cm]')\n",
        "    plt.legend(loc='upper left')\n",
        "    plt.show()\n",
        "\n",
        "X, y = load_iris(return_X_y=True, as_frame=True)\n",
        "\n",
        "y = y.iloc[0:100].values\n",
        "y = np.where(y == 1, 0, 1)\n",
        "\n",
        "X = X.iloc[0:100, [0, 2]].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YxHdjatQTJIF"
      },
      "outputs": [],
      "source": [
        "### -------------------------------------------------------------------------------------------- ###\n",
        "# Utiliza la clase Perceptron para predecir sobre el dataset compuesto por las variables \"X\" e \"Y\" #\n",
        "### -------------------------------------------------------------------------------------------- ###\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z61ZaTB2TJIG"
      },
      "source": [
        "1.7 Utiliza la función \"plot_errors_over_epochs\" para visualizar el proceso de entrenamiento de tu modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Le3xDkPLTJIG"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZ6heLSKTJIH"
      },
      "source": [
        "1.8 Utiliza la función \"plot_decision_regions\" para ver qué tal separa tu modelo el dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "whaXphQ7TJIH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Pd0MQjHTJIH"
      },
      "source": [
        "# 2. Implementar Adaline en Python"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zMK8Y02lTJII"
      },
      "source": [
        "Utilizando la implementación del perceptrón del ejercicio anterior, modifícala en la siguiente celda para tener un modelo Adaline.\n",
        "\n",
        "- Las funciones \"net_input\" y \"predict\" son exactamente iguales.\n",
        "- En la función \"activation\", deberás implementar la función de activación de Adaline, que si recuerdas, se definía: $f(X) = X$\n",
        "- En la función \"fit\", deberás modificar los valores de actualización de $W$ y $b$ para que cuadren con el modelo de Adaline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DQFzrcm2TJII"
      },
      "outputs": [],
      "source": [
        "class Adaline:\n",
        "    \"\"\"Adaline classifier.\n",
        "    Parameters\n",
        "    ------------\n",
        "    eta : float\n",
        "      Learning rate (between 0.0 and 1.0)\n",
        "    n_iter : int\n",
        "      Passes over the training dataset.\n",
        "    random_state : int\n",
        "      Random number generator seed for random weight\n",
        "      initialization.\n",
        "    Attributes\n",
        "    -----------\n",
        "    w_ : 1d-array\n",
        "      Weights after fitting.\n",
        "    b_ : Scalar\n",
        "      Bias unit after fitting.\n",
        "    errors_ : list\n",
        "      Number of misclassifications (updates) in each epoch.\n",
        "    \"\"\"\n",
        "    def __init__(self, eta=0.01, n_iter=50, random_state=1):\n",
        "        self.eta = eta\n",
        "        self.n_iter = n_iter\n",
        "        self.random_state = random_state\n",
        "        rgen = np.random.RandomState(self.random_state)\n",
        "        self.w_ = rgen.normal(loc=0.0, scale=0.01, size=X.shape[1])\n",
        "        self.b_ = np.float_(0.)\n",
        "        self.errors_ = []\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        \"\"\"Ajusta los vectores de X a la clase y.\n",
        "        Parámetros\n",
        "        ----------\n",
        "        X : {array-like}, shape = [n_examples, n_features]\n",
        "          Vectores de entrenamiento, donde n_examples es el número de vectores,\n",
        "          y n_features, el número de features por cada vector.\n",
        "        y : array-like, shape = [n_examples]\n",
        "          Vector de ground truth.\n",
        "        Returns\n",
        "        -------\n",
        "        self : object\n",
        "        \"\"\"\n",
        "\n",
        "    def net_input(self, X):\n",
        "        \"\"\"Calcula el net input entre X y W\"\"\"\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"Retorna la clase a la que pertenece el registro X\"\"\"\n",
        "\n",
        "    def activation(self, X):\n",
        "        \"\"\"Función de activación de Adaline\"\"\""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.10.6 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.6"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}