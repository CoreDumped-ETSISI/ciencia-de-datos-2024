{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "loP_9sANuj-p"
      },
      "source": [
        "Vamos a aprender a utilizar Pytorch con operaciones que nos demuestren las ventajas de su uso.\n",
        "\n",
        "1.1. Crea un array de NumPy y un tensor de Pytorch en base a la siguiente lista de Python:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TGBP2spEuj-r"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "seed = 64\n",
        "random.seed(seed)\n",
        "lista = [[float(random.randint(0, 9)) for i in range(0, 5000)] for i in range(0, 5000)]\n",
        "np_array =\n",
        "t_tensor ="
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQvTQUnF5J5c"
      },
      "source": [
        "1.2. Completa la función \"inverse_numpy\". Esta función deberá recibir como parámetro un array de numpy de dos dimensiones, y devolver la matriz inversa correspondiente, utilizando numpy. Utilízala para invertir `np_array`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TF5UoOzc1xwU"
      },
      "outputs": [],
      "source": [
        "def inverse_numpy(array: np.array) -> np.array:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNPZbM0B5cTE"
      },
      "source": [
        "1.3. Completa la función \"inverse_torch\". Esta función deberá recibir como parámetro un tensor de torch de dos dimensiones y el dispositivo en el que ejecutar la operación, y devolver la matriz inversa correspondiente, utilizando torch. Utilízala para invertir `t_tensor`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G4Fx6J6X2nlv"
      },
      "outputs": [],
      "source": [
        "def inverse_torch(tensor: torch.tensor, device: str) -> torch.tensor:\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "npFTh3Bb5oHq"
      },
      "source": [
        "1.4. Utiliza la siguiente función para comparar cuánto tardan las funciones que has creado. Compara inverse_numpy contra inverse_torch en cpu contra inverse_torch en CUDA."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pj1Qg8uL3Nal"
      },
      "outputs": [],
      "source": [
        "from timeit import default_timer as timer\n",
        "\n",
        "def time_inverses(inv_function):\n",
        "    start_time = timer()\n",
        "    inv_function()\n",
        "    end_time = timer()\n",
        "    time_taken = end_time - start_time\n",
        "    print(f\"tiempo: {time_taken}\")\n",
        "\n",
        "inverse_numpy_l = lambda: inverse_numpy(t_tensor)\n",
        "inverse_torch_cpu = lambda: inverse_torch(t_tensor, \"cpu\")\n",
        "inverse_torch_gpu = lambda: inverse_torch(t_tensor, \"cuda\")\n",
        "\n",
        "time_inverses(inverse_numpy_l)\n",
        "time_inverses(inverse_torch_cpu)\n",
        "time_inverses(inverse_torch_gpu)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mUIvFrMrAeAj"
      },
      "source": [
        "# Entrenar un modelo multicapa\n",
        "\n",
        "Vamos a utilizar un modelo multicapa para predecir sobre el dataset iris de sklearn. Primero, ejecuta la siguiente celda para conseguir la X y la y."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DJVdJTk2AgN8"
      },
      "outputs": [],
      "source": [
        "# ----------- Ejecuta esta celda ----------- #\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "iris = load_iris()\n",
        "X = iris['data']\n",
        "y = iris['target']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=1./3, random_state=1)\n",
        "\n",
        "torch.manual_seed(1)\n",
        "\n",
        "X_train_norm = (X_train - np.mean(X_train)) / np.std(X_train)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "diUlvVveBIzZ"
      },
      "source": [
        "2.1. Convierte la X_train_norm y la y_train en un [TensorDataset](https://pytorch.org/docs/stable/data.html?highlight=tensordataset#torch.utils.data.TensorDataset) de torch. Recuerda que primero debes convertir la X y la y en tensores. Después, introduce ese dataset en un [DataLoader](https://pytorch.org/docs/stable/data.html?highlight=dataloader#torch.utils.data.DataLoader) de torch, con batch_size de 2 y shuffle igual a True."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q1_kRhmaAmWn"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import TensorDataset\n",
        "from torch.utils.data import DataLoader\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Wz5olPKCSSR"
      },
      "source": [
        "2.2. Construye el modelo. Este debe tener dos capas [lineales y completamente conectadas](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html).\n",
        "- Primero, construye cada capa dentro del método `__init__()` como atributos de la clase (recuerda que para ello, debes escribir `self` delante del nombre de la variable, como el `this` en Java).\n",
        "- Después, en el método `forward`, aplica primero la operación de la capa y después la función de activación, para cada una de las dos capas. La función de activación de la capa uno deberá ser una [sigmoide](https://pytorch.org/docs/stable/generated/torch.nn.Sigmoid.html), y la de la capa 2, una [Softmax con dim=1](https://pytorch.org/docs/stable/generated/torch.nn.Softmax.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EX12dFYsApJV"
      },
      "outputs": [],
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super().__init__()\n",
        "        # La definición de las capas va aquí\n",
        "        self.layer1 =\n",
        "        self.layer2 =\n",
        "\n",
        "    def forward(self, x):\n",
        "        # El proceso a través de las capas va aquí\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "25Ycla9LD_Wr"
      },
      "source": [
        "2.3. Define el tamaño de las capas. El tamaño de `input_size` viene dado por X. El de la capa oculta debe ser 16, y el de la capa de salida debe ser 3, ya que nuestra clase tiene tres valores posibles. Usa estos valores para construir un modelo con la clase `Model`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZMTpI4NuEO80"
      },
      "outputs": [],
      "source": [
        "input_size = X_train_norm.shape[1]\n",
        "hidden_size =\n",
        "output_size =\n",
        "\n",
        "model ="
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LsgiaFEpExy2"
      },
      "source": [
        "2.4. Define el learning_rate, la función de pérdida, y el optimizador.\n",
        "- El learning_rate deberá ser 0.001.\n",
        "- La función de pérdida deberá ser la de [entropía cruzada](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8DxVbP1fFI5y"
      },
      "outputs": [],
      "source": [
        "learning_rate =\n",
        "loss_fn =\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rx6JEe4jFV8z"
      },
      "source": [
        "2.5. Ejecuta el siguiente código para entrenar el modelo con los parámetros que has definido. Míralo con detenimiento para comprender qué está pasando."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GrqU0k8PAtJa"
      },
      "outputs": [],
      "source": [
        "num_epochs = 100\n",
        "loss_hist = [0] * num_epochs\n",
        "accuracy_hist = [0] * num_epochs\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    for x_batch, y_batch in train_dl:\n",
        "        pred = model(x_batch)\n",
        "        loss = loss_fn(pred, y_batch.long())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        loss_hist[epoch] += loss.item()*y_batch.size(0)\n",
        "        is_correct = (torch.argmax(pred, dim=1) == y_batch).float()\n",
        "        accuracy_hist[epoch] += is_correct.sum()\n",
        "\n",
        "    loss_hist[epoch] /= len(train_dl.dataset)\n",
        "    accuracy_hist[epoch] /= len(train_dl.dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bRCTX1iwFd-8"
      },
      "source": [
        "2.6. Ejecuta esta celda para ver cómo progresa tu modelo a lo largo de cada época."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yt0FS4wUA0Gh"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(12, 5))\n",
        "ax = fig.add_subplot(1, 2, 1)\n",
        "ax.plot(loss_hist, lw=3)\n",
        "ax.set_title('Training loss', size=15)\n",
        "ax.set_xlabel('Epoch', size=15)\n",
        "ax.tick_params(axis='both', which='major', labelsize=15)\n",
        "\n",
        "ax = fig.add_subplot(1, 2, 2)\n",
        "ax.plot(accuracy_hist, lw=3)\n",
        "ax.set_title('Training accuracy', size=15)\n",
        "ax.set_xlabel('Epoch', size=15)\n",
        "ax.tick_params(axis='both', which='major', labelsize=15)\n",
        "plt.tight_layout()\n",
        "\n",
        "#plt.savefig('figures/12_09.pdf')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LxyUnVInxCop"
      },
      "source": [
        "2.7. Utiliza el método `predict` del modelo para predecir sobre `X_test`. Recuerda que primero debes normalizar la X. Puedes ver cómo hacerlo en el apartado 2.1. Una vez lo tengas, utiliza el método [confusion_matrix](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html) para obtener una matriz de confusión y evaluar tu modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2FJ31rDWrxfX"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.6 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}